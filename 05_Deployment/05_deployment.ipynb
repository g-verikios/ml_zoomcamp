{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../03_Logistic_Regression/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2,  random_state=1)\n",
    "\n",
    "df_train_full = df_train_full.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep for training\n",
    "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
    "               'phoneservice', 'multiplelines', 'internetservice',\n",
    "               'onlinesecurity', 'onlinebackup', 'deviceprotection',\n",
    "               'techsupport', 'streamingtv', 'streamingmovies',\n",
    "               'contract', 'paperlessbilling', 'paymentmethod']\n",
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "columns = categorical + numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, columns, C):\n",
    "    \n",
    "    dicts = df_train[columns].to_dict(orient = 'records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse = False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', C=C) # we use max_iter to avoid warnings\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model, columns):\n",
    "    dicts = df[columns].to_dict(orient = 'records')\n",
    "    \n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1] # probabilities only for positive examples\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL FINAL TESTING\n",
    "\n",
    "with 5 fold evaluation to make sure our model is okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21f70b038a64e1b9d2db23c74be1bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01, 0.839 +- 0.009\n",
      "C=0.1, 0.841 +- 0.007\n",
      "C=1, 0.841 +- 0.007\n",
      "C=10, 0.841 +- 0.007\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "for C in tqdm([0.01, 0.1, 1, 10]):\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(df_full_train): \n",
    "\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train.churn.values\n",
    "        y_val = df_val.churn.values\n",
    "\n",
    "        dv, model = train(df_train, y_train, columns, C=C)\n",
    "\n",
    "        y_pred = predict(df_val, dv, model, columns)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%s, %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579400803839363"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = 1.0\n",
    "\n",
    "dv, model = train(df_full_train, df_full_train.churn.values, columns, C)\n",
    "\n",
    "y_test = df_test.churn.values\n",
    "\n",
    "y_pred = predict(df_test, dv, model, columns)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = f'model_C={C}.bin'\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open(output_file, 'wb') # open the file and write binary\n",
    "\n",
    "pickle.dump((dv, model), f_out) # write the vectorizer and the model, we need them both\n",
    "\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's common to forget to close the file so the ```with``` method is preffered. This is shorter and the file will always be closed, when out of the with statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'wb') as f_out:\n",
    "\n",
    "    pickle.dump((dv, model), f_out)\n",
    "\n",
    "    #do stuff\n",
    "\n",
    "#do other stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "now we read the file, so we use ```'rb'``` instead of ```'wb'``` its important to avoid to overwrite the file creating one with zero bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'model_C=1.0.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_file, 'rb') as f_in: # now we read the file, its important to avoid to overwrite the file creating one with zero bytes\n",
    "\n",
    "    (dv, model) = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(solver='liblinear'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read this correctly we need scikit learn installed, if we try to load pickle file with the model, but we dont need to import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a customer info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  , 29.85,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  , 29.85]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dv.transform([customer]) # remember that DictVectorizer expects a list\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6433013293502078"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[0,1] # Probabillity of a customer to churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making requests ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml-zoomcamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe17136f30b89012cec6faa8ca6177f3798e14f74e1b78655ff12a9457374e50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
